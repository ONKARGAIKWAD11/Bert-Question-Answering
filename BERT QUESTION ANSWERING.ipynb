{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046f4eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sci\\anaconda3\\lib\\site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sci\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sci\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24dbd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sci\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sci\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sci\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sci\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sci\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sci\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af859cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dce8800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6533c5d8d7964b02a41986ae92dce1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SCI\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SCI\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c59fd0a5cf4f7ca2c2f3b5cfa600fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5f46fba7064d3186433e52407892c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdf835708e8409e82e4fe13c9f91624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d92beffe914d4696612c02993c0693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    " \n",
    "tokenizer_for_bert = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47c33757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_question_answer(question, passage, max_len=500):\n",
    "    #Tokenize input question and passage \n",
    "    #Include unique tokens- [CLS] and [SEP]\n",
    "    input_ids = tokenizer_for_bert.encode(question, passage,  max_length= max_len, truncation=True)\n",
    "    #Getting number of tokens in 1st sentence (question) and 2nd sentence (passage that contains answer)\n",
    "    sep_index = input_ids.index(102) \n",
    "    len_question = sep_index + 1  \n",
    "    len_passage = len(input_ids)- len_question  \n",
    "    segment_ids =  [0]*len_question + [1]*(len_passage)  \n",
    "    #Converting token ids to tokens\n",
    "    tokens = tokenizer_for_bert.convert_ids_to_tokens(input_ids) \n",
    "    #Getting start and end scores for answer\n",
    "    #Converting input arrays to torch tensors before passing to the model\n",
    "    start_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]) )[0]\n",
    "    end_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]) )[1]\n",
    "    #Converting scores tensors to numpy arrays\n",
    "    start_token_scores = start_token_scores.detach().numpy().flatten()\n",
    "    end_token_scores = end_token_scores.detach().numpy().flatten()\n",
    "    #Getting start and end index of answer based on highest scores\n",
    "    answer_start_index = np.argmax(start_token_scores)\n",
    "    answer_end_index = np.argmax(end_token_scores)\n",
    "    #Getting scores for start and end token of the answer\n",
    "    start_token_score = np.round(start_token_scores[answer_start_index], 2)\n",
    "    end_token_score = np.round(end_token_scores[answer_end_index], 2)\n",
    "    #Combining subwords starting with ## and get full words in output. \n",
    "    #It is because tokenizer breaks words which are not in its vocab.\n",
    "    answer = tokens[answer_start_index] \n",
    "    for i in range(answer_start_index + 1, answer_end_index + 1):\n",
    "        if tokens[i][0:2] == '##':  \n",
    "            answer += tokens[i][2:] \n",
    "        else:\n",
    "            answer += ' ' + tokens[i]  \n",
    " \n",
    "    # If the answer didn't find in the passage\n",
    "    if (start_token_score < 0 ) or ( answer_start_index == 0) or ( answer_end_index <  answer_start_index) or (answer == '[SEP]'):\n",
    "        answer = \"Sorry!, I was unable to discover an answer in the passage.\"\n",
    "     \n",
    "    return (answer_start_index, answer_end_index, start_token_score, end_token_score,  answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f3ee22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me define one passage\n",
    "passage = \"\"\"John say Let's assign tasks for the launch.\n",
    "Amy say I'll handle the marketing strategy.\n",
    "David say I'll take care of the product design.\n",
    "Lisa say I'll manage the content creation.\n",
    "David say We need at least 3 months for design.\n",
    "Amy say Marketing can be ready in 2 months.\n",
    "Lisa say Content creation will take 2.5 months.\n",
    "Let's aim for a 4-month launch timeline.\n",
    "David say I'll create a design proposal.\n",
    "Amy say I'll work on the marketing plan.\n",
    "john say onkar i'm assigning you a work that is start working on content planning\"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc08cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1016c25f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      " what work did john assign to onkar \n",
      "\n",
      "Answer:  start working on content planning \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question1 =\"what work did john assign to onkar \"\n",
    "print ('\\nQuestion 1:\\n', question1)\n",
    "_, _ , _ , _, ans  = bert_question_answer( question1, passage)\n",
    "print('\\nAnswer: ', ans ,  '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d294ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      " who will work on marketing plan\n",
      "\n",
      "Answer:  amy\n"
     ]
    }
   ],
   "source": [
    "question1 =\"who will work on marketing plan\"\n",
    "print ('\\nQuestion 1:\\n', question1)\n",
    "_, _ , _ , _ , ans  = bert_question_answer( question1, passage)\n",
    "print('\\nAnswer: ', ans )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44c35c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      " what is main goal of this meeting?\n",
      "\n",
      "Answer :  4 - month launch timeline \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question1 =\"what is main goal of this meeting?\"\n",
    "print ('\\nQuestion 1:\\n', question1)\n",
    "_, _ , _ , _, ans  = bert_question_answer( question1, passage)\n",
    "print('\\nAnswer : ', ans ,  '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "649cc22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      " John is assigning task for?\n",
      "\n",
      "Answer from BERT:  the launch \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question1 =\"John is assigning task for?\"\n",
    "print ('\\nQuestion 1:\\n', question1)\n",
    "_,_,_,_, ans  = bert_question_answer( question1, passage)\n",
    "print('\\nAnswer from BERT: ', ans ,  '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a2133bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      " marketing will be ready in how many month?\n",
      "\n",
      "Answer from BERT:  2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question1 =\"marketing will be ready in how many month?\"\n",
    "print ('\\nQuestion 1:\\n', question1)\n",
    "_,_,_,_, ans  = bert_question_answer( question1, passage)\n",
    "print('\\nAnswer from BERT: ', ans ,  '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "257273ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      " what is time duration for timeline launch?\n",
      "\n",
      "Answer from BERT:  4 - month \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question1 =\"what is time duration for timeline launch?\"\n",
    "print ('\\nQuestion 1:\\n', question1)\n",
    "_, _ , _ , _, ans  = bert_question_answer( question1, passage)\n",
    "print('\\nAnswer from BERT: ', ans ,  '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a2b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f9bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d2b7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca98507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
